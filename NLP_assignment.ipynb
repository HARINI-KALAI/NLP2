{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExkFuro6YxYm",
        "outputId": "9e181148-91da-48f2-add4-99562902aca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: ['Machine', 'Learning', 'is', 'the', 'most', 'powerful', 'weapon', 'specified', 'in', 'classification']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "corpus = \"\"\"Machine Learning is the most powerful weapon specified in classification\"\"\"\n",
        "\n",
        "unigrams = word_tokenize(corpus)\n",
        "print(\"Unigrams:\",unigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import bigrams\n",
        "\n",
        "bigrams_list = list(bigrams(corpus))\n",
        "print(\"Bigrams:\",bigrams_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tNdegXBa_EH",
        "outputId": "9288f9cc-304c-4fed-e7d5-d8dd8f9880ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams: [('M', 'a'), ('a', 'c'), ('c', 'h'), ('h', 'i'), ('i', 'n'), ('n', 'e'), ('e', ' '), (' ', 'L'), ('L', 'e'), ('e', 'a'), ('a', 'r'), ('r', 'n'), ('n', 'i'), ('i', 'n'), ('n', 'g'), ('g', ' '), (' ', 'i'), ('i', 's'), ('s', ' '), (' ', 't'), ('t', 'h'), ('h', 'e'), ('e', ' '), (' ', 'm'), ('m', 'o'), ('o', 's'), ('s', 't'), ('t', ' '), (' ', 'p'), ('p', 'o'), ('o', 'w'), ('w', 'e'), ('e', 'r'), ('r', 'f'), ('f', 'u'), ('u', 'l'), ('l', ' '), (' ', 'w'), ('w', 'e'), ('e', 'a'), ('a', 'p'), ('p', 'o'), ('o', 'n'), ('n', ' '), (' ', 's'), ('s', 'p'), ('p', 'e'), ('e', 'c'), ('c', 'i'), ('i', 'f'), ('f', 'i'), ('i', 'e'), ('e', 'd'), ('d', ' '), (' ', 'i'), ('i', 'n'), ('n', ' '), (' ', 'c'), ('c', 'l'), ('l', 'a'), ('a', 's'), ('s', 's'), ('s', 'i'), ('i', 'f'), ('f', 'i'), ('i', 'c'), ('c', 'a'), ('a', 't'), ('t', 'i'), ('i', 'o'), ('o', 'n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(corpus)\n",
        "bigrams_list = list(bigrams(tokens))\n",
        "print(\"Bigrams:\")\n",
        "for bigram in bigrams_list:\n",
        "    print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJhoclg0byV7",
        "outputId": "da073f21-da65-4809-d267-06170194f113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams:\n",
            "('Machine', 'Learning')\n",
            "('Learning', 'is')\n",
            "('is', 'the')\n",
            "('the', 'most')\n",
            "('most', 'powerful')\n",
            "('powerful', 'weapon')\n",
            "('weapon', 'specified')\n",
            "('specified', 'in')\n",
            "('in', 'classification')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import trigrams\n",
        "\n",
        "tokens = word_tokenize(corpus)\n",
        "trigrams_list = list(trigrams(tokens))\n",
        "\n",
        "print(\"Trigrams:\")\n",
        "for trigram in trigrams_list:\n",
        "    print(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZTVWzUhcXyR",
        "outputId": "bc58d8ce-5826-4055-96de-a35079011d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigrams:\n",
            "('Machine', 'Learning', 'is')\n",
            "('Learning', 'is', 'the')\n",
            "('is', 'the', 'most')\n",
            "('the', 'most', 'powerful')\n",
            "('most', 'powerful', 'weapon')\n",
            "('powerful', 'weapon', 'specified')\n",
            "('weapon', 'specified', 'in')\n",
            "('specified', 'in', 'classification')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, FreqDist, ConditionalFreqDist\n",
        "from nltk.util import bigrams\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('punkt')\n",
        "text_corpus = \"\"\"Machine Learning is the most powerful weapon specified in classification\"\"\"\n",
        "tokens = word_tokenize(text_corpus)\n",
        "\n",
        "\n",
        "bigram_list = list(bigrams(tokens))\n",
        "unigram_freq = FreqDist(tokens)\n",
        "bigram_freq = FreqDist(bigram_list)\n",
        "\n",
        "bigram_prob = defaultdict(dict)\n",
        "for (w1, w2), freq in bigram_freq.items():\n",
        "    bigram_prob[w1][w2] = freq / unigram_freq[w1]\n",
        "\n",
        "print(\"Bigram Probabilities:\")\n",
        "for w1 in bigram_prob:\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        print(f\"P({w2} | {w1}) = {bigram_prob[w1][w2]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTzLSrSjc0mo",
        "outputId": "99ff75ac-d6ed-4eaf-f924-9c7d55624e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Probabilities:\n",
            "P(Learning | Machine) = 1.0000\n",
            "P(is | Learning) = 1.0000\n",
            "P(the | is) = 1.0000\n",
            "P(most | the) = 1.0000\n",
            "P(powerful | most) = 1.0000\n",
            "P(weapon | powerful) = 1.0000\n",
            "P(specified | weapon) = 1.0000\n",
            "P(in | specified) = 1.0000\n",
            "P(classification | in) = 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, FreqDist, ConditionalFreqDist\n",
        "from nltk.util import bigrams\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "text_corpus = \"\"\"Machine Learning is the most powerful weapon specified in classification\"\"\"\n",
        "\n",
        "tokens = word_tokenize(text_corpus)\n",
        "\n",
        "bigram_list = list(bigrams(tokens))\n",
        "bigram_freq = ConditionalFreqDist(bigram_list)\n",
        "\n",
        "def predict_next_word(current_word, bigram_freq):\n",
        "    if current_word not in bigram_freq:\n",
        "        return None\n",
        "    return bigram_freq[current_word].max()\n",
        "\n",
        "current_word = \"Machine\"\n",
        "next_word = predict_next_word(current_word, bigram_freq)\n",
        "print(f\"The next word after '{current_word}' is '{next_word}'.\")\n",
        "\n",
        "current_word = \"most\"\n",
        "next_word = predict_next_word(current_word, bigram_freq)\n",
        "print(f\"The next word after '{current_word}' is '{next_word}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-qj5G9YfCp0",
        "outputId": "5d652beb-c781-41bd-e2dd-b7bcce6b3465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The next word after 'Machine' is 'Learning'.\n",
            "The next word after 'most' is 'powerful'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}